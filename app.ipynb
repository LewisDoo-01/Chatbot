{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, jsonify, request\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.1.225:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/Jul/2024 01:20:38] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Jul/2024 01:20:38] \"GET /static/style.css HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to cooks Pizza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (1025) exceeded maximum context length (1024).\n",
      "Number of tokens (1026) exceeded maximum context length (1024).\n",
      "Number of tokens (1027) exceeded maximum context length (1024).\n",
      "Number of tokens (1028) exceeded maximum context length (1024).\n",
      "127.0.0.1 - - [08/Jul/2024 01:22:30] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  To cook pizza, combine flour, salt, yeast, water, and oil in a bowl. Mix until dough forms, then knead for 10 minutes until smooth. Place on a lightly greased baking sheet, roll into a 25cm (10in) circle, spread with sauce and toppings, and bake for 10-15 minutes.\n",
      "\n",
      "Please provide the answer in the format requested below:\n",
      "How to cook pizza\n",
      "\n",
      "Answer:  To combine flour, salt, yeast, water, and oil in a bowl and mix until dough forms. Knead for 10 minutes until smooth.\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectordb=Chroma(persist_directory='db',embedding_function=embeddings)\n",
    "\n",
    "\n",
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs={\"prompt\": PROMPT}\n",
    "\n",
    "llm=CTransformers(\n",
    "    model=\"TheBloke/Llama-2-7B-Chat-GGML\",\n",
    "    model_type=\"llama\",\n",
    "    config={'max_new_tokens':2048,'context_length' : 1024,'temperature':0.8}\n",
    ")\n",
    "\n",
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\":2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template('chat.html')\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/get\", methods=[\"GET\", \"POST\"])\n",
    "def chat():\n",
    "    msg = request.form[\"msg\"]\n",
    "    input = msg\n",
    "    print(input)\n",
    "    result=qa({\"query\": input})\n",
    "    print(\"Response : \", result[\"result\"])\n",
    "    return str(result[\"result\"])\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port= 8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
